{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "C4_W1_Assignment_Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXdEnmVvXdUa"
      },
      "source": [
        "# Train Your Own Model and Serve It With TensorFlow Serving\n",
        "\n",
        "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcLTAmF5Xs2T"
      },
      "source": [
        "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access. If you want to run it in a local Jupyter notebook, please proceed with caution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Q8bkjeYTl-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8r89tTPI-Kb",
        "outputId": "4de117d1-3de5-4614-e640-5e35ed371d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGFJmWjrKttn",
        "outputId": "49ee24e5-7f71-4fc6-ac86-d8125ac69c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â€¢ Using TensorFlow Version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq-214o8SNt0"
      },
      "source": [
        "## Import the MNIST Dataset\n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
        "\n",
        "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "outputId": "f46e2e61-c82a-48dc-a8bd-047e982ef2fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIT-qX0QzLo-"
      },
      "source": [
        "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIDGu-EEzdKb"
      },
      "source": [
        "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
        "\n",
        "```python\n",
        "train_images.shape: (60000, 28, 28, 1)\n",
        "test_images.shape: (10000, 28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsIxeG6BzN4t"
      },
      "source": [
        "# EXERCISE: Reshape the arrays below.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUw8ZxigB1Nx",
        "outputId": "3d8f6066-7c83-411c-8d03-012187d7f196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
        "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_images.shape: (60000, 28, 28, 1), of float64\n",
            "test_images.shape: (10000, 28, 28, 1), of float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcR0OKbOSj0c"
      },
      "source": [
        "## Look at a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQMs4v_oSo9v",
        "outputId": "02eb910f-9e9c-4829-ed56-32b05ee4a22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "idx = 42\n",
        "\n",
        "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn_-9OsPYnDp"
      },
      "source": [
        "## Build a Model\n",
        "\n",
        "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgMgJJynMbVY",
        "outputId": "d6416151-7c93-4e7b-a1c5-1bad1ed0b61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# EXERCISE: Create a model.\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,\n",
        "                               strides=2, activation='relu', name='Conv1'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 13, 13, 8)         80        \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1352)              0         \n",
            "                                                                 \n",
            " Softmax (Dense)             (None, 10)                13530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,610\n",
            "Trainable params: 13,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLzXnZT1YvS6"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNN0ANGgA36",
        "outputId": "582bb37f-4ae1-4f76-ebca-c8967a108278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# EXERCISE: Configure the model for training.\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# EXERCISE: Train the model.\n",
        "history = model.fit(train_images, train_labels, epochs=epochs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 19s 6ms/step - loss: 0.3802 - accuracy: 0.8946\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2095 - accuracy: 0.9413\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1466 - accuracy: 0.9594\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1166 - accuracy: 0.9667\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0994 - accuracy: 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er_vrDhf4qu5"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMD387B93f2g",
        "outputId": "faa41664-082f-43ee-8583-ae928ac976b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# EXERCISE: Evaluate the model on the test images.\n",
        "results_eval = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "for metric, value in zip(model.metrics_names, results_eval):\n",
        "    print(metric + ': {:.3}'.format(value))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.0943\n",
            "accuracy: 0.971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmT8M1Yx5y"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFDoDW_7HX6",
        "outputId": "ea60bdd7-449c-428e-f6f4-cefc9bd94cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Conv1_input with unsupported characters which will be renamed to conv1_input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "export_path = /tmp/1\n",
            "total 112\n",
            "drwxr-xr-x 2 root root  4096 May 12 13:02 assets\n",
            "-rw-r--r-- 1 root root    56 May 12 13:02 fingerprint.pb\n",
            "-rw-r--r-- 1 root root  8612 May 12 13:02 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 89982 May 12 13:02 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 May 12 13:02 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KziE3e9tY-hH"
      },
      "source": [
        "## Examine Your Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4GDF_aYtfQ",
        "outputId": "0ae6f757-6880-4c93-f331-b805c8b2d25a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-12 13:02:10.677120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['Conv1_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_Conv1_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['Softmax'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'Relu', 'ShardedFilename', 'Conv2D', 'StatefulPartitionedCall', 'Const', 'DisableCopyOnRead', 'StringJoin', 'Identity', 'NoOp', 'SaveV2', 'ReadVariableOp', 'BiasAdd', 'VarHandleOp', 'Reshape', 'MatMul', 'RestoreV2', 'MergeV2Checkpoints', 'AssignVariableOp', 'Pack', 'Softmax', 'Placeholder', 'StaticRegexFullMatch', 'Select'}\n",
            "2023-05-12 13:02:14.033585: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsDTdBGHZAzo"
      },
      "source": [
        "## Add TensorFlow Serving Distribution URI as a Package Source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWg9X2QHlbGS",
        "outputId": "d85711c6-bd9f-488b-8f90-3417e33e0077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  48245      0 --:--:-- --:--:-- --:--:-- 48245\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:6 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [348 B]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:8 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [338 B]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,158 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,343 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,046 kB]\n",
            "Hit:17 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,573 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,681 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,213 kB]\n",
            "Fetched 12.4 MB in 3s (3,884 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l5XkzqNZNBU"
      },
      "source": [
        "## Install TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwa9AgRloYy",
        "outputId": "7d9b0596-e2f0-43a7-df88-441cf573d0f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.12.1 [430 MB]\n",
            "Fetched 430 MB in 4s (96.3 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.12.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.12.1) ...\n",
            "Setting up tensorflow-model-server (2.12.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd_PobAKZWW8"
      },
      "source": [
        "## Run the TensorFlow Model Server\n",
        "\n",
        "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
        "\n",
        "* `rest_api_port`: Use port `8501` for your requests.\n",
        "\n",
        "\n",
        "* `model_name`: Use `digits_model` as your model name. \n",
        "\n",
        "\n",
        "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUgp3vUdU5GS"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDhHNJVnaLN"
      },
      "source": [
        "# EXERCISE: Fill in the missing code below.\n",
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=digits_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxbeiOCUUs2z"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mUrIWVRZdNu"
      },
      "source": [
        "## Create JSON Object with Test Images\n",
        "\n",
        "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dsD7KQG1m-R"
      },
      "source": [
        "# EXERCISE: Create JSON Object\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRdyPl4CZ5CU"
      },
      "source": [
        "## Make Inference Request\n",
        "\n",
        "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGvFyuIzW6n6"
      },
      "source": [
        "# EXERCISE: Fill in the code below\n",
        "\n",
        "# if this cell fails execution because of an \"...Failed to establish a new connection...\" error,\n",
        "# try replacing in the link below 'localhost' with '127.0.0.1'\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://127.0.0.1:8501/v1/models/digits_model:predict', data=data, headers=headers)\n",
        "\n",
        "predictions = json.loads(json_response.text)['predictions']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtrFMts_ackX"
      },
      "source": [
        "## Plot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxQzj34aiDz1",
        "outputId": "14263f08-6598-4f14-bf80-3faeadd77c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
        "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1500 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAEjCAYAAAC1qnceAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhDElEQVR4nO3deXRV5bnH8V8mAiEEwmAYBBLCKIhQUAaZFERA6gWUQYMaHEqlot5WqSKI0QgKFFFEsfVWCoSCiMhQEAEBQWYaQSYJkODQAElIEAkhITn3Dxaxh8B7cjhvcjJ8P2uxVs9+9n73k7R5ml/2OXv7OBwOhwAAAADAIl9vNwAAAACg7CFoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaJQS4dPDFf1ZdP7rDUkb5BPjow1JG6ydwyfGR69seMXaegBKDmYIAE8xR+Auf283UBrM/ma2Riwdkf860C9QDao2UO/I3hrfbbzCgsO82J17Vias1I6fduiVHq94uxWXfGJ8rlnr1aiX1jy0phi7Aa4fM6T45TnyNGfPHH168FPFn4jX6fOnFVEtQsNaDdNznZ9TRf+K3m4RcAtzxDt2/LRDs7+Zre0/bdfek3t1Me+iHBMc3m6r1CBouOHVHq8qIjRCWReztPn7zXp/1/tambBS+0btU1BAULH20q1hN51/6bwq+FVw67iVCSs1c+fMq/5wn3/pvPx9S87/JOYOnFtg267/7NLb299W70a9vdAR4BlmSPHJzMnUiKUj1PHGjvp9u9/rhso3aOuPWzVhwwStS1ynLx/+Uj4+1/5jBlBSMUeK18qElfrw3x+qdVhrNQptpMNph73dUqlScv6bLAX6Numr9nXbS5Ie/83jqlGphqZtm6alh5bqgZsfuOox57LPqXKFytZ78fXxtf4XuZL2F77hrYcX2LYhaYN85HPN7zdQkjFDik8Fvwr6+tGv1bl+5/xtT7R7QuHVwvPDRq9GvbzYIXB9mCPF68n2T+rPt/9ZlQIq6amVTxE03MRnNDxwZ8SdkqTEjERJUvRn0QqeGKyjp4+qX1w/VZlURVGfRkm6dBl/+rbpavleS1WMraiwqWEauXyk0s+nO63pcDgU+1Wsbpx2o4JeD9Id/7hD+0/tL3Dua70vcvuP29Uvrp9C3wxV5YmV1fr91np729v5/c3cOVPSpbclXf532dXeFxmfHK++cX0VMilEwROD1XNOT237cZvTPrO/mS2fGB99/f3X+uPqP6rWlFqqPLGyBi4cqJRzKU77nsk6o0Oph3Qm60xhvsVOLly8oMUHF6t7eHfdGHKj28cDJQ0z5JKimCEV/Co4hYzLBjYfKEk6mHLQeDxQWjBHLimq30XCgsNUKaCSy/1wdVzR8MDR9KOSpBqVauRvu5h3UXfPu1tdGnTR1Lum5l/GHLl8pGbvma0RbUbo6dueVmJGot7d8a7iT8Tr60e/VoBfgCTp5fUvK3ZTrPo16ad+jfvp38n/Vu95vZWdm+2ynzVH16j/P/urTnAdPdPhGdUOrq2DKQe1ImGFnun4jEa2G6n/nP2P1hxbc9W3JV1p/6n96vpRV4UEhmjM7WMU4BugD3Z/oB6ze2hj9EZ1uLGD0/6jV41WaKVQTeg+QUkZSZq+bbqe8ntKC+9fmL/PkkNLNGLpCH30Px8puk20yx7+28qElcrIylDUzVFuHQeUVMyQ4p0hknTilxOSpJpBNd0+FiiJmCPFP0dQeAQNN5zJOqPUzFRlXczS199/rVc3vqpK/pXUv2n//H0u5F7Q4JsGa1KvSfnbNn+/WR/Gf6i4QXF68OYH87ffEX6H+sT10aIDi/TgzQ8q5VyKJm+ZrHua3KPlDyzPf//wS+te0sTNE4295eblauSKkaoTXEff/P4bVatYLb/mcFz60FKn+p3UtEZTrTm25qpvS7rSuPXjlJOXo82Pblaj0EaSpIdveVjN3m2mMWvHaGP0Rqf9awTV0BfDv8jvO8+Rp3e2v6MzWWdUtWJVl+dzJe7bOAX6Ber+m+73eC3AG5gh3p0hkjR5y2SFBIaob5O+VtYDihtzxPtzBIXHW6fc0GtuL9WaUkv136qvYYuHKbhCsJYMXaJ6IfWc9nvy1iedXi/av0hVA6vqrkZ3KTUzNf9fu7rtFFwhWOsT10uS1h5bq+zcbI2+bbTThxSf7fisy97iT8QrMSNRz3Z81ukHW9J1feAxNy9XXxz9QgOaD8j/wZakOlXq6MGbH9Tm7zfr5ws/Ox3zu9/8zulcXRt0Va4jV8fPHM/fFt0mWo4JDrf/gvDzhZ/1r4R/qV+TfgW+PqC0YIZ4b4ZI0sRNE7X22Fq90fMN5ghKLeaId+cI3MMVDTfM7DdTTWs0lb+vv8Iqh6lZzWby9XHOav6+/gU+P5BwOkFnLpzRDVNvuOq6pzJPSVL+D0GTGk2c6rUq11JoxVBjb0dPX7p02uqGVoX/ggxSMlOUmZOpZjWaFai1qNlCeY48/XDmB7W8oWX+9gZVGzjtF1rpUs9Xvvfzeiw+sFhZF7N42xRKNWbIJd6YIQv3LdS4L8fpsbaPFfgFDChNmCOXeGOOwH0EDTfcVu+2/Ds9XEugX2CBH/g8R55uqHyD4gbFXfWYWkG1rPXoTX6+flfd7pDn95uO+zZOVQOrOl0aBkobZohZUc2QNUfX6OHPHtY9Te/RrP6zPFoL8DbmiFlR/i4C9xE0ikFkaKTWHlur2+vfbrxzQcOqDSVJCWkJTpcIU86lKD3LnMQjq0dKkvad2me8ZaOPCnfpslZQLQUFBOm7tO8K1A6lHpKvj6/qV61fqLU8lXw2WeuT1iv6lmgF+gcWyzmBkoQZcv22/7hdAxcOVPu67fXx/R+XqPvzA8WJOQJv4DMaxWBIyyHKdeTqta9eK1C7mHdRGVkZki497TrAN0AzdszI/9CUJE3fNt3lOX5T5zeKqBah6dum56932X+vdfk+2lfucyU/Xz/1juytpYeWKikjKX/7yV9Oav6++erSoItCAkNc9nWl67m97YJ9C5TnyFNUa942hfKJGfIrd2bIwZSDumf+PQqvFq4VD6zgFpUo15gjv/LkVvtwD3/aKQbdw7trZLuRmrR5kr458Y16R/ZWgG+AEk4naNGBRXq7z9u6/6b7VatyLT3X+TlN2jxJ/f/ZX/0a91P8iXitOrLK5a0YfX189f497+u3//yt2sxqoxFtRqhOlTo6lHpI+1P2a/Xw1ZKkdnXaSZKeXvW07o68W36+fhrWathV14y9I1Zrjq5Rl7930ahbR8nf118f7P5AFy5e0ORek6/re3E9t5SL+zZOdavUVY/wHtd1TqC0Y4b8qrAz5OyFs7p73t1Kz0rX852f178S/uVUjwyNVKf6na6rB6A0Yo78yp3fRY5nHNfcvZduw7vrP7su9fRVrKRLV38euuWh6+qhvCBoFJNZ/WepXZ12+mD3Bxq7bqz8ff0VXi1cw28ertvr356/X+ydsaroX1Gzds3S+sT16nBjB30x/AvdM/8el+e4u/HdWv/IesVsjNFftv5FeY48RVaP1BO/eSJ/n0EtBmn0baO1YN8Czds7Tw45rvnD3fKGlto0YpNeXPeiJm2epDxHnjrU66B5A+cVuG91Ufku9TvtTt6tP3b8Y4H3mwLlCTPEPWnn0/TDzz9Ikl5Y90KB+iO3PELQQLnDHHFfYkaixq8f77Tt8uvuDbsTNFzwcfz3tSwAAAAAsIA/EQMAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGnLyy4RX5xPgoNTPV2prRn0UrfHq4tfUAlFzMEACeYo6UHTywz8AnxqdQ+61/ZL1Xn1rdY3YPpWamat+ofV7roahsSNqgO/5xxzXrsXfE6qVuLxVjR0DhMUO8Ly0zTX+P/7uWH16ug6kHlZObo+Y1m+t/O/6vhrYa6u32AJeYIyXDwn0Ltfzwcm3/abuOnD6i7g27a0P0Bm+3VeIRNAzmDpzr9HrOnjlac2xNge0tarYozrbKlRY1WxT4fkvS3L1z9cXRL9Q7srcXugIKhxnifVt/3KqXvnxJ/Zr007iu4+Tv66/FBxdr2OJhOpByQDF3xHi7RcCIOVIyvL/rfe1O3q1b696qtMw0b7dTahA0DIa3Hu70etuP27Tm2JoC26+UmZOpoICgomyt3AgLDrvq9ztmY4yaVG+iW+vd6oWugMJhhnhfy1otlTA6QQ2rNczfNurWUeo1t5fe/PpNjbl9jCpXqOzFDgEz5kjJMHfgXNULqSdfH1+1eq+Vt9spNfiMhod6zO6hVu+10u7/7Fa3j7op6PUgjV03VtKly52vbHilwDHh08MV/Vm007aMrAw9+/mzqv9WfQXGBqrxO4315uY3lefIs9Ln3pN7Ff1ZtBq93UgVYyuq9tTaenTpo9dM5amZqRqyaIhCJoWoxuQaembVM8q6mFVgv3l756ndX9up0uuVVP3N6hr2yTD9cOYHl/0kn03WodRDysnNcftr2fHTDh05fURRN0e5fSxQ0jBDinaGRIRGOIUMSfLx8dGAZgN0IfeCjqUfc3kuoKRjjhT97yL1q9aXrw+/NruLKxoWpJ1PU9+4vhrWapiGtx6usMphbh2fmZOp7rO766eff9LIdiPVoGoDbflxi15c96KSf0nW9D7TPe5xzdE1OpZ+TCPajFDt4Nran7Jff939V+1P2a9tj22Tj4/ze0CHLBqi8GrhmtRzkrb9tE3v7HhH6VnpmjNwTv4+r3/1usavH68hLYfo8baPKyUzRTN2zFC32d0UPzJe1SpWu2Y/L657Uf/Y8w8lPpOo8Grhbn0tcXvjJElRrQkaKBuYIcU7QyTpxC8nJEk1g2q6fSxQEjFHin+OwDWChgUnfjmhWffM0sj2I6/r+Glbp+no6aOKHxmvJjWaSJJGth+pusF1NWXLFP2p059Uv2p9j3ocdeso/anzn5y2dbyxox5Y/IA2f79ZXRt2dapFhEZo6bClkqQ/6A8KqRCi93a9p+c6P6fWYa11POO4JmyYoNg7YzW269j84wa1GKS2H7TVezvfc9puS25erhbuX6jb6t2mxtUbW18f8AZmSPHNEEk6ff60Poz/UF0bdFWdKnWK5BxAcWOOFO8cQeFwDciCQL9AjWg74rqPX3Rgkbo27KrQSqFKzUzN/9erUS/lOnL11fGvPO6xUkCl/P+cdTFLqZmp6nhjR0nSv5P/XWD/P9z6B6fXozuMliStTFgpSfr04KfKc+RpSMshTj3XDq6tJtWbaH3SemM/swfMlmOCw+2/IKxLXKeT507ytimUKcyQ4psheY48RX0apYysDM3oO8OtY4GSjDlSfHMEhccVDQvqhdRTBb8K1318QlqC9p7cq1pTal21furcqete+7LT508rZkOMFuxfUGC9MxfOFNi/SfUmTq8jQyPl6+OrpIykSz2fTpBDDjWZ0aTAsZIU4Bfgcc9XE/dtnPx8/DS0JbelRNnBDCmoqGbI6JWj9fmRzzVnwBzdUvuWIjkH4A3MkYKKao6g8AgaFlTyr+R6p/+S68h1ep3nyNNdje7SmNvHXHX/pjWaXndvlw1ZNERbftii5zs/rza12yi4QrDyHHnqE9enUB/yuvJ9k3mOPPnIR6uiVsnP16/A/sEVgj3u+Urnc85rycEl6tWol8KC3XvvKVCSMUOKZ4bEbIjRe7ve0xs939BDtzxkfX3Am5gjxTNH4B6CRhEKrRiqjKwMp23ZudlKPpvstC2yeqR+yf5FvRr1KpI+0s+na13iOsX0iNHL3V/O356QlnDNYxJOJygiNCL/9ZHTR5TnyMu/vBgZGimHHIoIjbAyfApj2XfLdDb7LG+bQrnBDLFn5o6ZemXjK3q2w7P6c5c/F/n5gJKCOQJv4jMaRSiyemSB9zT+dfdfC/wVYchNQ7T1x61afWR1gTUysjJ0Me+iR31cTvkOh8Np+/Rt0695zMydM51ez9h+6b3MfRv3lXTpg1Z+Pn6K2RhTYF2Hw+HyYTbXc3vb+fvmKyggSANbDCz0MUBpxgy5NndmyMJ9C/X0508r6uYoTbt7msv9gbKEOXJtntxqH4XDFY0i9Hjbx/X7f/1e9318n+5qdJf2nNij1UdXF7id4vO3P69lh5ep/z/7K/qWaLWr207nss/p21Pf6pMDnyjp2SSXt2BMyUxR7FexBbZHVItQVOsodWvYTZO3TFZOXo7qVamnL459ocT0xGuul5ieqHv/ea/6NO6jrT9u1by98/TgzQ/mv6c5snqkYu+M1YvrXlRSRpIGNBugKoFVlJieqCWHluh37X6n5zo/d8313b2l3Onzp7UqYZXuu+k+LoWi3GCGeD5Ddvy0Qw9/9rBqVKqhnhE9FfdtnFO9c/3OahTayPi9AUoz5oid30W+Ov5VfmBLyUzRuZxz+V9rt4bd1K1hN+Px5RVBowg90e4JJWYk6v/i/0+fH/lcXRt01ZqH1qjnnJ5O+wUFBGlj9EZN3DRRiw4s0py9cxQSGKKmNZoqpkeMqgZWdXmuU+dOafz68QW294zoqajWUZo/aL5GrxqtmTtnyuFwqHdkb62KWqW60+pedb2F9y/Uyxte1gtrX5C/r7+euvUpTek9xWmfF7q8oKY1muqtbW8pZmOMpEsPtOkd2Vv3Nru3sN+mQlm0f5Fy8nL0YKsHra4LlGTMEM8dSDmg7NxspWSm6NFljxaof/Q/HxE0UKYxR+z4MvHL/PUvu/y1Tug+gaBxDT6OK681AQAAAICH+IwGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwzt/bDQAACm/q1Kku9zl//ryxvnfvXmP9k08+caunKz355JPGeqdOnYz1hx56yKPzAwBKBq5oAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKzzcTgcDm83AQC4ZOjQocb6okWLiqmTotO4cWNjfe3atS7XaNCgga12AJQyhw8fNtabNWvmco133nnHWB89erRbPeHquKIBAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACs8/d2AwBQnpSE52Q0b97cWO/Tp4+xfuzYMWN92bJlxvqRI0eM9Xnz5hnrkjR27FiX+wAom+Lj4411X1/Xf0evV6+erXZgwBUNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHc/RAACLdu3aZawvWbLEo/VbtWrlch9Xz7GoWbOmsR4cHGysZ2dnG+sdOnQw1vfs2WOsp6WlGesAyrdvvvnGWHc1wyRp0KBBlrqBCVc0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdeXqORqffPKJsf63v/3NWK9bt66xXrFiRWM9KirKWJek2rVrG+uNGzd2uQYA70lOTjbWHQ6Hse7qORmrV6922UOdOnVc7uOJqVOnGusHDx70aP3+/ft7dDyA0u3bb7811mfMmGGsP/zwwzbbgQe4ogEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwrV8/ReP755431pKSkIj3/rFmzXO4TEhJirN9000222im16tevb6yPGTPGWG/fvr3NdgAnv/3tb431I0eOGOtVqlQx1qtXr+52T7YtXLjQWM/Ozi6mTgCURd99952xfu7cOWN96NChNtuBB7iiAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCtXz9H48MMPjfU9e/YY666eYXHgwAFjPT4+3liXpA0bNhjr27ZtM9YbNGhgrH///fcue/BEQECAy31q1qxprCcnJxvrrr4Hrp6zwXM04E0NGzb0dgsuTZkyxVg/fPiwR+t36NDBozqAsm3y5MnGenh4uLHO/8+XHFzRAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1vk4HA6Ht5vAr9LT0411V8/icHXv6J07d7rdkzsCAwNd7tOsWTNjvXnz5sb66dOnjfWZM2ca66NGjTLWgbJuxYoVxvrgwYON9QsXLhjrYWFhxvqCBQuM9e7duxvrAEq3pKQkYz0iIsJYd/V7xKFDh9xtCUWEKxoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6/y93QCchYaGGut33nmnR+v37NnTo+NtWLx4sbHu6qGFrVu3NtaHDRvmdk9AebJr1y5j3dUD+VwZOnSosc4D+YDybePGjR4dX6tWLUudoKhxRQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFjHczRg1alTp1zuM2rUKGPd4XAY6y+//LKxXr16dZc9AGXZgAEDjPXVq1d7tP4jjzxirMfGxnq0PoCybe/evR4dP2bMGEudoKhxRQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFjHczRg1cyZM13u4+pZG9WqVTPWmzVr5k5LQJmSnJzscp8tW7YY6xcuXDDWa9WqZayPGzfOWA8ODjbWAZRtW7duNdY/+ugjY71t27bG+l133eV2T/AOrmgAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADreI4G3LJ582Zj/Y033vD4HEuXLjXWW7Vq5fE5gNJq0KBBLvdJTU316BxRUVHGemRkpEfrAyjb1q1bZ6ynp6cb63369DHWK1as6HZP8A6uaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOt4jgbcsnLlSmM9Ozvb5Rq9evUy1jt16uRWT0BZsmzZMmM9Pj7e43P06NHDWH/11Vc9PgeA8mvPnj0eHT948GBLncDbuKIBAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACs4zkacHL+/Hlj/fPPPzfWAwMDXZ4jJibGWA8ICHC5BlBapaWlGesTJ0401gvzrBpX2rRpY6wHBwd7fA4AZdeJEyeM9U2bNhnrzZs3N9YHDhzodk8ombiiAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArOM5GnAyZcoUYz0+Pt5Y79u3r8tzdO7c2a2egLLkL3/5i7G+Y8cOj88xYMAAY/3VV1/1+BwAyq/Zs2cb6ydPnjTWC/O7AsoGrmgAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArOOBfeXMihUrjPXXXnvNWK9ataqxPn78eLd7AsqTadOmFfk5Zs6caawHBwcXeQ8Ayq7jx497dHxoaKilTlDScUUDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYx3M0ypi0tDRj/emnnzbWL168aKz369fPWO/UqZOxDqDouZoDAQEBxdTJ1bl6Hk9h+svJyTHWz5w541ZPV0pPTzfW33rrLY/WLww/Pz9j/c033zTWg4KCbLYD5Fu+fLlHx/fv399SJyjpuKIBAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACs4zkapUxubq6x3qdPH2M9MTHRWG/cuLGx/tprrxnrALyvdevW3m7BaMiQIcZ6nTp1XK5x8uRJY33BggVu9VQahYWFGevjxo0rpk5Q1mzatMlYd/XzB1zGFQ0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdz9EoZY4ePWqs79q1y6P1p02bZqxHRkZ6tD5Q3vXr189Y/+yzz4qnES/6+OOPvd2CAgICjHVfX8/+Dnfvvfca6+3bt/dofUnq0qWLx2sAV7NkyRJj/eLFi8Z627ZtjfXu3bu73RNKJ65oAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA63iORglz/PhxY713794erT916lRjvX///h6tD8Ds008/NdYnT55srGdnZ9ts56oOHDhgrC9YsKBIz//YY4+53Kdhw4YeneO+++4z1lu0aOHR+kBJlZmZ6XKfVatWeXSOwYMHG+t+fn4erY/SgysaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOh+Hw+HwdhP41dixY431SZMmebT+zp07jfX27dt7tD4AACi5cnJyXO7TrVs3Yz0sLMxYnz9/vrEeFBTksgeUDVzRAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1vl7u4HyZNOmTS73effdd4uhEwAAUB4FBAS43Gfr1q3F0AnKA65oAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKzjgX3FaPPmzS73OXv2rEfnaNy4sbEeHBzs0foAAABAYXBFAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWMdzNEqZNm3aGOvr1q0z1qtXr26xGwAAAODquKIBAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACs83E4HA5vNwEAAACgbOGKBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOv+H9/ZZCIHBxoeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}